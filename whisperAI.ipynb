{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himani-Trivedi/30-days-Code/blob/main/whisperAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkooYyEayaXf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neah6IITye8x",
        "outputId": "d3e6d9fd-9f22-4575-aa11-81a159be5d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230918.tar.gz (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (17.0.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=0a1bebaf893077ca19e2e05d78895febe06cab6c4a32ab38c27e684655587616\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20230918 tiktoken-0.3.3\n"
          ]
        }
      ],
      "source": [
        "pip install -U openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7MnBh86zgBa",
        "outputId": "c9e75e0d-dd38-4f7a-9449-b4cdfc56bcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-1f9bqyiq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-1f9bqyiq\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=3ba6134b7c566e46ef171095c70ab7d78f0504b1f97685ac6e9d8e352225d854\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9mm330cs/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "#to get access to openai whisper api\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R3D_QAz3BqM",
        "outputId": "cab868e2-34ff-45d9-93e6-7bd7fc8bff94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [48.6 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,046 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,247 kB]\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,326 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,599 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,153 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,305 kB]\n",
            "Fetched 8,976 kB in 4s (2,487 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg\n",
        "#to enable access to audio & video files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6Xx4HTB_zH6"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5PCRr6MAz28i"
      },
      "outputs": [],
      "source": [
        "import whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVFhpckB2uk6",
        "outputId": "4ba0d96e-53e4-4739-c8d0-a6d82b055470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:10<00:00, 44.0MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0357EYE12y3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ccf5f0-babb-4eaa-fb7a-35b917f78b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Book a car from home to office.\n"
          ]
        }
      ],
      "source": [
        "result = model.transcribe(\"sample_data/h_o.m4a\",language=\"en\")\n",
        "print(result['text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2=model.transcribe(\"sample_data/o_h.m4a\",language=\"en\")\n",
        "print(result2['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3R9BoErUu48",
        "outputId": "c2565d0c-4d01-4b3c-f654-c3fd61fa7fa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Book a car from office to home.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1u8KlWZB6_tM"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_to_locations(text):\n",
        "    # Define regular expressions for \"from\" and \"to\" patterns\n",
        "    from_pattern = re.compile(r'\\bfrom\\s+(\\w+)\\b', re.IGNORECASE)\n",
        "    to_pattern = re.compile(r'\\bto\\s+(\\w+)\\b', re.IGNORECASE)\n",
        "\n",
        "    # Apply regular expressions to the text\n",
        "    from_match = re.search(from_pattern, text)\n",
        "    to_match = re.search(to_pattern, text)\n",
        "\n",
        "    from_location = from_match.group(1) if from_match else None\n",
        "    to_location = to_match.group(1) if to_match else None\n",
        "\n",
        "    return from_location, to_location"
      ],
      "metadata": {
        "id": "5d8leuANVNyE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from_l, to_l=extract_from_to_locations(result2['text'])\n",
        "print(from_l,to_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWmlZ2RfVN0k",
        "outputId": "c5423367-503b-497b-e569-9094ac0740c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(12, 23), match='from office'>\n",
            "<re.Match object; span=(24, 31), match='to home'>\n",
            "office home\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLeEBQPQVN3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eySYB_gxVN5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-h4Tg_xVN7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajzs5YQs6_59"
      },
      "outputs": [],
      "source": [
        "#loading hindi video file to check for other laguages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxfysE3T303x"
      },
      "outputs": [],
      "source": [
        "result_hin=model.transcribe(audio=\"muskurao.mp4\", language=\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPr7nXcY6hi-",
        "outputId": "ea8c7278-3aab-4a64-d756-219b26ff2802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " a small piece and when i say that smile you have to do something to smile smile if you have lost it from today someone might have been more important than you smile if something has happened the person who was born maybe he has gone smile if you have lost it for someone to be born maybe someone has to break and if you have lost it then just be scared then break it and if you are happy in your heart then just be in the same process be scared when you think about it that it is good it is good then think about it that it is bad then what happens? be scared if you have a good clothes and you have a good clothes and if you have to be scared then just be scared be scared when someone is living their lives what is the difference? be scared that we have been scared be scared be scared even if you have to walk miles and miles because it is okay if your glass is half empty you can always feel it with miles be scared\n"
          ]
        }
      ],
      "source": [
        "print(result_hin['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqNXm8mN772y"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS02YCP36hlM",
        "outputId": "2ba68c4d-e9c5-4af9-f957-ca09163aa3d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:06<00:00, 74.3MiB/s]\n",
            "[00:00.000 --> 00:05.880]  अप्स्मूल पीस और मैं जब जब कब मुसकुराओ अपको खुष निकरनें बस्मुसकुराऊँ\n",
            "[00:05.880 --> 00:08.760]  मुसकुराओ अगर अज कहीं से हार गए हो\n",
            "[00:08.760 --> 00:12.800]  किसी को उस जीट की तुमसे जाएडा जारुरत थी शायत\n",
            "[00:12.800 --> 00:15.880]  मुसकुराओ अगर कुच को गया है\n",
            "[00:16.600 --> 00:19.200]  जिसके नसीप का ता उसको मिल गया है शायत\n",
            "[00:19.200 --> 00:22.680]  मुसकुराओ अगर दिल तुट आया है\n",
            "[00:22.680 --> 00:26.840]  किसी का जोरने के लिए किसी का तोरना परता होगा शायत\n",
            "[00:26.840 --> 00:30.320]  और रह जाए अगर दिल में फिर भी दरत कहीं\n",
            "[00:30.320 --> 00:34.320]  तो बांट कर मुसकुराओ और है अगर दिल में खुषी जाएडा\n",
            "[00:34.440 --> 00:36.320]  तो सें प्रोसेस दूराओ\n",
            "[00:36.320 --> 00:40.320]  मुसकुराओ जब बार भार येश शोचकर हताश हो जाते हो\n",
            "[00:40.320 --> 00:43.920]  कि इस से अच्छा ये होजाता इस से अच्छा वो होजाता\n",
            "[00:43.920 --> 00:48.320]  तब ये सोचकर मुसकुराओ कि इस से बुरा होजाता तो क्या होजाता\n",
            "[00:48.320 --> 00:52.320]  मुसकुराओ अगर सर्पे है च्छत बदन पर कप्रा होर है थाली में खाना\n",
            "[00:52.320 --> 00:56.320]  और है अगर जरुरत से जाएडा तो बाट कर गराना\n",
            "[00:56.320 --> 01:00.320]  मुसकुराओ जब पुछे कोई कि जिन्दगी जीने का है क्या सली का\n",
            "[01:01.320 --> 01:04.320]  मुसकुराओ ये कैकर कि हमने जिन्दगी से मुसकुराना ही से का\n",
            "[01:04.320 --> 01:06.320]  मुसकुराओ\n",
            "[01:06.320 --> 01:10.320]  मुसकुराओ even if you have to walk miles and miles\n",
            "[01:10.320 --> 01:13.320]  because it's okay if your glass is half empty\n",
            "[01:13.320 --> 01:15.320]  you can always fill it with smiles\n",
            "[01:15.320 --> 01:16.320]  मुसकुराओ\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#direct download txt file\n",
        "\n",
        "!whisper muskurao.mp4 --language Hindi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0WGpz7y6hnd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtpBkyQn6hrB",
        "outputId": "ec66887d-747b-453f-8733-78c16bede287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Hindi\n",
            "[00:00.000 --> 00:03.400]  A small piece, and whenever I say to smile,\n",
            "[00:03.400 --> 00:05.380]  you don't have to do anything, you just have to smile.\n",
            "[00:05.380 --> 00:08.980]  Smile, if you have lost somewhere today.\n",
            "[00:08.980 --> 00:13.100]  Maybe someone needed more than you to win that victory.\n",
            "[00:13.100 --> 00:16.340]  Smile, if you have lost something.\n",
            "[00:16.340 --> 00:19.900]  The one who had the fortune has got it, maybe.\n",
            "[00:19.900 --> 00:23.340]  Smile, if your heart is broken.\n",
            "[00:23.340 --> 00:27.140]  Maybe someone will have to break someone to join someone.\n",
            "[00:27.240 --> 00:32.240]  And if you still have pain in your heart, then smile.\n",
            "[00:32.240 --> 00:36.240]  And if you are happy in your heart, then come back to the same process.\n",
            "[00:36.240 --> 00:40.240]  Smile, when you think about it again and again,\n",
            "[00:40.240 --> 00:43.740]  that it would have been better than this, it would have been better than that.\n",
            "[00:43.740 --> 00:45.240]  Then think about it and smile.\n",
            "[00:45.240 --> 00:48.240]  What would have happened if it would have been worse than this?\n",
            "[00:48.240 --> 00:51.340]  Smile, if you have clothes on your head,\n",
            "[00:51.340 --> 00:53.140]  and you have food in the plate,\n",
            "[00:53.140 --> 00:56.340]  and if you are more than needed, then come back home.\n",
            "[00:56.440 --> 01:00.840]  Smile, when you ask someone what is the right way to live life.\n",
            "[01:00.840 --> 01:04.840]  Smile, saying that we have learned to smile from life.\n",
            "[01:04.840 --> 01:10.340]  Smile, smile even if you have to walk miles and miles.\n",
            "[01:10.340 --> 01:13.340]  Because it's okay, if your glass is half empty,\n",
            "[01:13.340 --> 01:15.140]  you can always fill it with smiles.\n",
            "[01:15.140 --> 01:16.340]  Smile.\n"
          ]
        }
      ],
      "source": [
        "#translates defualt audio to english by defualt by specifying task as translate\n",
        "\n",
        "!whisper muskurao.mp4 --task translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UfcyaBP8Vyh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upd0gS5o8Vz7"
      },
      "outputs": [],
      "source": [
        "#we can specify audio file name with the laguage of the audio if possible then translate it into english using task\n",
        "\n",
        "# !whisper file-name --language language-name --task translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtuKULj78V-S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B285XGS4fAQ"
      },
      "outputs": [],
      "source": [
        "#deconing to other language\n",
        "\n",
        "audio=whisper.load_audio('sample_data/demo_audio.mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhuxE6zu5MRA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "19OoJtenH-opJTO8tMJA53W3bTLfmtGK6",
      "authorship_tag": "ABX9TyOz0gUkSRFynZlP6VfNidKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}